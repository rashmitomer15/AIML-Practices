{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Questions - Project 2 - Sequential Models in NLP - Sarcasm Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7SIeJ_oZMU"
      },
      "source": [
        "<img src=\"http://drive.google.com/uc?export=view&id=1tpOCamr9aWz817atPnyXus8w5gJ3mIts\" width=500px>\n",
        "\n",
        "Proprietary content. Â© Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eukag7wEoPZu"
      },
      "source": [
        "### Package Version:\n",
        "- tensorflow==2.2.0\n",
        "- pandas==1.0.5\n",
        "- numpy==1.18.5\n",
        "- google==2.0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp68FAQf9aMN"
      },
      "source": [
        "# Sarcasm Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEahVPtWX5ve"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "#### Acknowledgement\n",
        "Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n",
        "\n",
        "**Required Files given in below link.**\n",
        "\n",
        "https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAk6BRUh8CqL"
      },
      "source": [
        "### Load Data (3 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1kww5erpRRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "042e3bc9-874a-4498-e5c9-ef125e7dee17"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m4h54e1n5tO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5c457978-9a23-4620-b9b6-a4a708063d50"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/ClassNotes/Lab9-Seq models in NLP/SarcasmDetection\")\n",
        "os.getcwd()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/ClassNotes/Lab9-Seq models in NLP/SarcasmDetection'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8-PQsV0DrAZ"
      },
      "source": [
        "def parseJson(fname):\n",
        "    for line in open(fname, 'r'):\n",
        "        yield eval(line)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIX13Zw_nzZa"
      },
      "source": [
        "data = list(parseJson('./Data/Sarcasm_Headlines_Dataset.json'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v-qvxStp693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "233c6230-bd0c-477a-f7c5-897e389e6eef"
      },
      "source": [
        "data[4]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'article_link': 'https://www.huffingtonpost.com/entry/jk-rowling-wishes-snape-happy-birthday_us_569117c4e4b0cad15e64fdcb',\n",
              " 'headline': 'j.k. rowling wishes snape happy birthday in the most magical way',\n",
              " 'is_sarcastic': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNwr2gtLuaE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ed3dd1e4-a2ce-48f8-f429-b34af193ea8e"
      },
      "source": [
        "dfObj = pd.DataFrame(data) \n",
        "dfObj.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        article_link  ... is_sarcastic\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
              "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
              "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR_LukCirLSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a92005-9b60-415c-adaa-3194a3b3ea71"
      },
      "source": [
        "dfObj.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26709, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6pXf7A78E2H"
      },
      "source": [
        "### Drop `article_link` from dataset (3 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUNHq5zEV0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b786b0-e636-4d65-a316-8e54266267e0"
      },
      "source": [
        "dfObj.columns"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['article_link', 'headline', 'is_sarcastic'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAfGIbqqvcqD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8d69e4c3-b64d-45ed-b563-6d493d4da002"
      },
      "source": [
        "dfObj=dfObj.drop(['article_link'], axis=1)\n",
        "dfObj.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  former versace store clerk sues over secret 'b...             0\n",
              "1  the 'roseanne' revival catches up to our thorn...             0\n",
              "2  mom starting to fear son's web series closest ...             1\n",
              "3  boehner just wants wife to listen, not come up...             1\n",
              "4  j.k. rowling wishes snape happy birthday in th...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0h6IOxU8OdH"
      },
      "source": [
        "### Get length of each headline and add a column for that (3 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLpiBRDmEV2l"
      },
      "source": [
        "dfObj['length']=dfObj.apply(lambda row: len(row[\"headline\"]), axis = 1) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAusEP4jxrup",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "91b23209-9b9b-4ad8-c06b-e35d62df902a"
      },
      "source": [
        "dfObj.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic  length\n",
              "0  former versace store clerk sues over secret 'b...             0      78\n",
              "1  the 'roseanne' revival catches up to our thorn...             0      84\n",
              "2  mom starting to fear son's web series closest ...             1      79\n",
              "3  boehner just wants wife to listen, not come up...             1      84\n",
              "4  j.k. rowling wishes snape happy birthday in th...             0      64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS9MwYISDyRW",
        "outputId": "b828c6a3-6845-4fbd-d513-ce5def02731b"
      },
      "source": [
        "dfObj[\"length\"].max()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMF-wjJ2aMwm"
      },
      "source": [
        "### Initialize parameter values\n",
        "- Set values for max_features, maxlen, & embedding_size\n",
        "- max_features: Number of words to take from tokenizer(most frequent words)\n",
        "- maxlen: Maximum length of each sentence to be limited to 25\n",
        "- embedding_size: size of embedding vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPw9gAN_EV6m"
      },
      "source": [
        "max_features = 10000\n",
        "maxlen = 25\n",
        "embedding_size = 200"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V1mTtZroKyQ"
      },
      "source": [
        "Splitting the Data into test and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Gg0lwqoIEX"
      },
      "source": [
        "# Splitting the dataset into Train and Test\n",
        "training_size = round(len(dfObj['headline']) * .75)\n",
        "\n",
        "training_sentences = dfObj['headline'][0:training_size]\n",
        "testing_sentences = dfObj['headline'][training_size:]\n",
        "\n",
        "training_labels = dfObj[\"is_sarcastic\"][0:training_size]\n",
        "testing_labels = dfObj[\"is_sarcastic\"][training_size:]\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9abSe-bM8fn9"
      },
      "source": [
        "### Apply `tensorflow.keras` Tokenizer and get indices for words (3 Marks)\n",
        "- Initialize Tokenizer object with number of words as 10000\n",
        "- Fit the tokenizer object on headline column\n",
        "- Convert the text to sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8g4l0KfF3eh"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokeniser = Tokenizer(num_words=10000)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQyZZmve0y84"
      },
      "source": [
        "# Fit the tokenizer on Training data\n",
        "tokeniser.fit_on_texts(training_sentences)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wyvRsGM1R2y"
      },
      "source": [
        "training_sequences = tokeniser.texts_to_sequences(training_sentences)\n",
        "\n",
        "testing_sequences = tokeniser.texts_to_sequences(testing_sentences)\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeZpwPO4bOkZ"
      },
      "source": [
        "### Pad sequences (3 Marks)\n",
        "- Pad each example with a maximum length\n",
        "- Convert target column into numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScHHOV3MsRZK"
      },
      "source": [
        "# Creating padded sequences from train and test data\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "training_padded = pad_sequences(training_sequences, maxlen=maxlen,\n",
        "                                padding=padding_type, truncating=trunc_type)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=maxlen, \n",
        "                               padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qWFWwXCtNTa"
      },
      "source": [
        "# Converting the lists to numpy arrays for Tensorflow 2.x\n",
        "training_padded = np.array(training_padded)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_padded = np.array(testing_padded)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8qInkaX2GNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a87594-a26c-4481-b475-a689a408c337"
      },
      "source": [
        "is_sarcastic_array =  dfObj[[\"is_sarcastic\"]].values\n",
        "is_sarcastic_array[0:5]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJLyKg-98rH_"
      },
      "source": [
        "### Vocab mapping\n",
        "- There is no word for 0th index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCNgtnQqdbZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8be59e-6acf-40a8-c093-fd341fe8dc55"
      },
      "source": [
        "tokeniser.word_index"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'to': 1,\n",
              " 'of': 2,\n",
              " 'the': 3,\n",
              " 'in': 4,\n",
              " 'for': 5,\n",
              " 'a': 6,\n",
              " 'on': 7,\n",
              " 'and': 8,\n",
              " 'with': 9,\n",
              " 'is': 10,\n",
              " 'new': 11,\n",
              " 'trump': 12,\n",
              " 'man': 13,\n",
              " 'from': 14,\n",
              " 'at': 15,\n",
              " 'about': 16,\n",
              " 'you': 17,\n",
              " 'by': 18,\n",
              " 'this': 19,\n",
              " 'after': 20,\n",
              " 'be': 21,\n",
              " 'up': 22,\n",
              " 'out': 23,\n",
              " 'that': 24,\n",
              " 'how': 25,\n",
              " 'as': 26,\n",
              " 'it': 27,\n",
              " 'not': 28,\n",
              " 'are': 29,\n",
              " 'your': 30,\n",
              " 'what': 31,\n",
              " 'his': 32,\n",
              " 'all': 33,\n",
              " 'he': 34,\n",
              " 'who': 35,\n",
              " 'will': 36,\n",
              " 'just': 37,\n",
              " 'has': 38,\n",
              " 'more': 39,\n",
              " 'one': 40,\n",
              " 'year': 41,\n",
              " 'into': 42,\n",
              " 'report': 43,\n",
              " 'have': 44,\n",
              " 'why': 45,\n",
              " 'over': 46,\n",
              " 'area': 47,\n",
              " 'u': 48,\n",
              " 'donald': 49,\n",
              " 'says': 50,\n",
              " 'day': 51,\n",
              " 'can': 52,\n",
              " 's': 53,\n",
              " 'first': 54,\n",
              " 'woman': 55,\n",
              " 'time': 56,\n",
              " 'like': 57,\n",
              " 'old': 58,\n",
              " 'get': 59,\n",
              " 'her': 60,\n",
              " 'no': 61,\n",
              " \"trump's\": 62,\n",
              " 'off': 63,\n",
              " 'now': 64,\n",
              " 'an': 65,\n",
              " 'life': 66,\n",
              " 'people': 67,\n",
              " 'obama': 68,\n",
              " 'women': 69,\n",
              " 'house': 70,\n",
              " \"'\": 71,\n",
              " 'white': 72,\n",
              " 'was': 73,\n",
              " 'still': 74,\n",
              " 'back': 75,\n",
              " 'make': 76,\n",
              " 'than': 77,\n",
              " 'down': 78,\n",
              " 'clinton': 79,\n",
              " 'when': 80,\n",
              " 'my': 81,\n",
              " '5': 82,\n",
              " 'could': 83,\n",
              " 'world': 84,\n",
              " 'americans': 85,\n",
              " 'if': 86,\n",
              " 'i': 87,\n",
              " 'we': 88,\n",
              " 'way': 89,\n",
              " 'their': 90,\n",
              " 'most': 91,\n",
              " 'study': 92,\n",
              " 'they': 93,\n",
              " 'before': 94,\n",
              " 'family': 95,\n",
              " 'do': 96,\n",
              " 'gop': 97,\n",
              " 'best': 98,\n",
              " 'black': 99,\n",
              " \"it's\": 100,\n",
              " 'bill': 101,\n",
              " 'school': 102,\n",
              " 'but': 103,\n",
              " 'only': 104,\n",
              " 'police': 105,\n",
              " 'so': 106,\n",
              " 'him': 107,\n",
              " 'years': 108,\n",
              " 'president': 109,\n",
              " 'know': 110,\n",
              " 'should': 111,\n",
              " '3': 112,\n",
              " 'last': 113,\n",
              " 'being': 114,\n",
              " 'watch': 115,\n",
              " 'would': 116,\n",
              " 'really': 117,\n",
              " '10': 118,\n",
              " 'video': 119,\n",
              " 'going': 120,\n",
              " 'show': 121,\n",
              " \"can't\": 122,\n",
              " 'death': 123,\n",
              " 'hillary': 124,\n",
              " 'american': 125,\n",
              " 'during': 126,\n",
              " 'things': 127,\n",
              " 'finds': 128,\n",
              " 'good': 129,\n",
              " 'state': 130,\n",
              " 'against': 131,\n",
              " 'she': 132,\n",
              " 'may': 133,\n",
              " 'home': 134,\n",
              " 'or': 135,\n",
              " 'love': 136,\n",
              " 'health': 137,\n",
              " 'say': 138,\n",
              " 'need': 139,\n",
              " 'nation': 140,\n",
              " 'too': 141,\n",
              " 'every': 142,\n",
              " '000': 143,\n",
              " 'right': 144,\n",
              " 'take': 145,\n",
              " 'gets': 146,\n",
              " 'campaign': 147,\n",
              " \"'the\": 148,\n",
              " 'work': 149,\n",
              " 'little': 150,\n",
              " '2': 151,\n",
              " 'mom': 152,\n",
              " 'some': 153,\n",
              " 'court': 154,\n",
              " 'getting': 155,\n",
              " 'party': 156,\n",
              " 'high': 157,\n",
              " 'john': 158,\n",
              " '7': 159,\n",
              " \"here's\": 160,\n",
              " 'our': 161,\n",
              " 'calls': 162,\n",
              " 'kids': 163,\n",
              " 'where': 164,\n",
              " 'takes': 165,\n",
              " 'parents': 166,\n",
              " 'makes': 167,\n",
              " 'child': 168,\n",
              " 'dead': 169,\n",
              " 'big': 170,\n",
              " 'these': 171,\n",
              " 'election': 172,\n",
              " 'local': 173,\n",
              " 'while': 174,\n",
              " 'own': 175,\n",
              " 'never': 176,\n",
              " 'real': 177,\n",
              " 'go': 178,\n",
              " 'news': 179,\n",
              " \"doesn't\": 180,\n",
              " 'other': 181,\n",
              " 'see': 182,\n",
              " \"he's\": 183,\n",
              " 'america': 184,\n",
              " 'self': 185,\n",
              " 'through': 186,\n",
              " '4': 187,\n",
              " 'want': 188,\n",
              " 'plan': 189,\n",
              " 'stop': 190,\n",
              " 'college': 191,\n",
              " 'guy': 192,\n",
              " '6': 193,\n",
              " 'its': 194,\n",
              " 'change': 195,\n",
              " 'look': 196,\n",
              " 'sex': 197,\n",
              " \"don't\": 198,\n",
              " 'gay': 199,\n",
              " 'office': 200,\n",
              " 'again': 201,\n",
              " 'two': 202,\n",
              " 'bush': 203,\n",
              " 'next': 204,\n",
              " \"nation's\": 205,\n",
              " 'around': 206,\n",
              " 'war': 207,\n",
              " 'even': 208,\n",
              " '1': 209,\n",
              " 'got': 210,\n",
              " 'another': 211,\n",
              " 'wants': 212,\n",
              " 'baby': 213,\n",
              " 'million': 214,\n",
              " 'long': 215,\n",
              " \"man's\": 216,\n",
              " 'thing': 217,\n",
              " 'dog': 218,\n",
              " 'them': 219,\n",
              " 'week': 220,\n",
              " 'north': 221,\n",
              " 'dad': 222,\n",
              " 'congress': 223,\n",
              " 'made': 224,\n",
              " 'gun': 225,\n",
              " 'much': 226,\n",
              " 'job': 227,\n",
              " 'care': 228,\n",
              " 'under': 229,\n",
              " 'ever': 230,\n",
              " 'national': 231,\n",
              " 'help': 232,\n",
              " 'finally': 233,\n",
              " '20': 234,\n",
              " 'debate': 235,\n",
              " 'actually': 236,\n",
              " 'ways': 237,\n",
              " 'us': 238,\n",
              " 'been': 239,\n",
              " 'students': 240,\n",
              " '9': 241,\n",
              " 'shows': 242,\n",
              " 'sexual': 243,\n",
              " 'give': 244,\n",
              " \"won't\": 245,\n",
              " 'season': 246,\n",
              " 'live': 247,\n",
              " 'game': 248,\n",
              " 'making': 249,\n",
              " 'better': 250,\n",
              " 'climate': 251,\n",
              " 'senate': 252,\n",
              " 'shooting': 253,\n",
              " 'without': 254,\n",
              " 'anti': 255,\n",
              " 'history': 256,\n",
              " 'media': 257,\n",
              " 'god': 258,\n",
              " 'night': 259,\n",
              " 'had': 260,\n",
              " 'star': 261,\n",
              " 'couple': 262,\n",
              " 'money': 263,\n",
              " 'entire': 264,\n",
              " 'everyone': 265,\n",
              " 'there': 266,\n",
              " 'city': 267,\n",
              " 'free': 268,\n",
              " 'trying': 269,\n",
              " 'any': 270,\n",
              " 'end': 271,\n",
              " 'law': 272,\n",
              " 'me': 273,\n",
              " 'children': 274,\n",
              " 'announces': 275,\n",
              " 'tv': 276,\n",
              " 'top': 277,\n",
              " 'found': 278,\n",
              " 'away': 279,\n",
              " 'paul': 280,\n",
              " 'supreme': 281,\n",
              " 'face': 282,\n",
              " '8': 283,\n",
              " 'men': 284,\n",
              " 'government': 285,\n",
              " 'teen': 286,\n",
              " 'come': 287,\n",
              " 'story': 288,\n",
              " 'tell': 289,\n",
              " 'business': 290,\n",
              " 'food': 291,\n",
              " 'part': 292,\n",
              " 'film': 293,\n",
              " 'bad': 294,\n",
              " 'reveals': 295,\n",
              " 'introduces': 296,\n",
              " 'think': 297,\n",
              " 'deal': 298,\n",
              " 'morning': 299,\n",
              " 'facebook': 300,\n",
              " 'does': 301,\n",
              " 'attack': 302,\n",
              " 'find': 303,\n",
              " 'james': 304,\n",
              " 'movie': 305,\n",
              " 'son': 306,\n",
              " 'car': 307,\n",
              " 'friend': 308,\n",
              " 'york': 309,\n",
              " '11': 310,\n",
              " 'enough': 311,\n",
              " 'fire': 312,\n",
              " 'power': 313,\n",
              " 'pope': 314,\n",
              " 'fight': 315,\n",
              " 'wedding': 316,\n",
              " 'used': 317,\n",
              " 'body': 318,\n",
              " 'book': 319,\n",
              " 'call': 320,\n",
              " 'middle': 321,\n",
              " \"didn't\": 322,\n",
              " 'girl': 323,\n",
              " 'run': 324,\n",
              " 'same': 325,\n",
              " 'use': 326,\n",
              " 'former': 327,\n",
              " 'tax': 328,\n",
              " 'single': 329,\n",
              " 'line': 330,\n",
              " 'thinks': 331,\n",
              " 'friends': 332,\n",
              " 'public': 333,\n",
              " 'second': 334,\n",
              " 'email': 335,\n",
              " 'support': 336,\n",
              " 'photos': 337,\n",
              " 'republican': 338,\n",
              " 'great': 339,\n",
              " 'asks': 340,\n",
              " 'rights': 341,\n",
              " 'sanders': 342,\n",
              " 'looking': 343,\n",
              " 'company': 344,\n",
              " 'behind': 345,\n",
              " 'marriage': 346,\n",
              " 'speech': 347,\n",
              " 'must': 348,\n",
              " 'claims': 349,\n",
              " 'room': 350,\n",
              " 'security': 351,\n",
              " 'already': 352,\n",
              " 'because': 353,\n",
              " 'each': 354,\n",
              " '2016': 355,\n",
              " 'keep': 356,\n",
              " 'judge': 357,\n",
              " 'team': 358,\n",
              " 'republicans': 359,\n",
              " 'christmas': 360,\n",
              " 'goes': 361,\n",
              " 'vote': 362,\n",
              " 'presidential': 363,\n",
              " 'democrats': 364,\n",
              " 'talk': 365,\n",
              " \"world's\": 366,\n",
              " 'might': 367,\n",
              " 'violence': 368,\n",
              " 'case': 369,\n",
              " 'inside': 370,\n",
              " 'voters': 371,\n",
              " 'control': 372,\n",
              " 'open': 373,\n",
              " 'ban': 374,\n",
              " 'future': 375,\n",
              " 'name': 376,\n",
              " 'win': 377,\n",
              " 'human': 378,\n",
              " 'department': 379,\n",
              " 'between': 380,\n",
              " 'ad': 381,\n",
              " 'wife': 382,\n",
              " 'coming': 383,\n",
              " 'perfect': 384,\n",
              " 'having': 385,\n",
              " 'twitter': 386,\n",
              " 'killed': 387,\n",
              " 'secret': 388,\n",
              " 'political': 389,\n",
              " 'fans': 390,\n",
              " 'full': 391,\n",
              " 'sure': 392,\n",
              " 'group': 393,\n",
              " 'very': 394,\n",
              " 'pretty': 395,\n",
              " 'student': 396,\n",
              " '12': 397,\n",
              " 'texas': 398,\n",
              " 'three': 399,\n",
              " 'bernie': 400,\n",
              " 'record': 401,\n",
              " 'once': 402,\n",
              " 'music': 403,\n",
              " '15': 404,\n",
              " 'missing': 405,\n",
              " 'releases': 406,\n",
              " 'poll': 407,\n",
              " 'doing': 408,\n",
              " 'teacher': 409,\n",
              " 'ready': 410,\n",
              " 'living': 411,\n",
              " 'super': 412,\n",
              " 'boy': 413,\n",
              " 'always': 414,\n",
              " 'scientists': 415,\n",
              " 'meet': 416,\n",
              " 'art': 417,\n",
              " 'here': 418,\n",
              " 'reports': 419,\n",
              " 'unveils': 420,\n",
              " 'save': 421,\n",
              " 'kim': 422,\n",
              " 'until': 423,\n",
              " 'photo': 424,\n",
              " 'race': 425,\n",
              " 'something': 426,\n",
              " 'working': 427,\n",
              " 'summer': 428,\n",
              " 'comes': 429,\n",
              " 'were': 430,\n",
              " 'fucking': 431,\n",
              " 'post': 432,\n",
              " 'obamacare': 433,\n",
              " 'shot': 434,\n",
              " 'start': 435,\n",
              " 'word': 436,\n",
              " 'running': 437,\n",
              " 'ryan': 438,\n",
              " 'california': 439,\n",
              " 'lives': 440,\n",
              " 'month': 441,\n",
              " 'mike': 442,\n",
              " 'thousands': 443,\n",
              " 'gives': 444,\n",
              " 'days': 445,\n",
              " 'wall': 446,\n",
              " 'leaves': 447,\n",
              " 'drug': 448,\n",
              " 'water': 449,\n",
              " 'head': 450,\n",
              " 'class': 451,\n",
              " 'female': 452,\n",
              " 'age': 453,\n",
              " 'looks': 454,\n",
              " 'social': 455,\n",
              " 'minutes': 456,\n",
              " 'many': 457,\n",
              " 'let': 458,\n",
              " 'country': 459,\n",
              " 'person': 460,\n",
              " 'put': 461,\n",
              " 'breaking': 462,\n",
              " 'everything': 463,\n",
              " 'father': 464,\n",
              " 'plans': 465,\n",
              " 'russia': 466,\n",
              " 'states': 467,\n",
              " 'town': 468,\n",
              " 'candidate': 469,\n",
              " 'forced': 470,\n",
              " 'tells': 471,\n",
              " 'cancer': 472,\n",
              " 'yet': 473,\n",
              " 'education': 474,\n",
              " 'left': 475,\n",
              " 'probably': 476,\n",
              " 'korea': 477,\n",
              " 'cruz': 478,\n",
              " 'dream': 479,\n",
              " \"'i\": 480,\n",
              " 'air': 481,\n",
              " 'place': 482,\n",
              " 'past': 483,\n",
              " 'admits': 484,\n",
              " 'employee': 485,\n",
              " 'taking': 486,\n",
              " 'hot': 487,\n",
              " 'believe': 488,\n",
              " 'biden': 489,\n",
              " 'did': 490,\n",
              " 'eating': 491,\n",
              " 'pay': 492,\n",
              " 'hard': 493,\n",
              " 'red': 494,\n",
              " \"you're\": 495,\n",
              " 'mother': 496,\n",
              " 'half': 497,\n",
              " 'street': 498,\n",
              " \"i'm\": 499,\n",
              " 'justice': 500,\n",
              " 'secretary': 501,\n",
              " 'beautiful': 502,\n",
              " 'guide': 503,\n",
              " 'romney': 504,\n",
              " 'administration': 505,\n",
              " '30': 506,\n",
              " 'south': 507,\n",
              " 'heart': 508,\n",
              " 'wins': 509,\n",
              " 'list': 510,\n",
              " 'dies': 511,\n",
              " 'military': 512,\n",
              " '50': 513,\n",
              " 'isis': 514,\n",
              " 'internet': 515,\n",
              " 'excited': 516,\n",
              " 'tips': 517,\n",
              " 'personal': 518,\n",
              " 'small': 519,\n",
              " 'young': 520,\n",
              " 'talks': 521,\n",
              " 'needs': 522,\n",
              " 'together': 523,\n",
              " 'fbi': 524,\n",
              " 'rock': 525,\n",
              " 'nuclear': 526,\n",
              " 'lost': 527,\n",
              " 'times': 528,\n",
              " 'questions': 529,\n",
              " 'michael': 530,\n",
              " 'fan': 531,\n",
              " 'lot': 532,\n",
              " 'those': 533,\n",
              " 'letter': 534,\n",
              " 'hollywood': 535,\n",
              " 'set': 536,\n",
              " 'crisis': 537,\n",
              " 'officials': 538,\n",
              " 'king': 539,\n",
              " 'owner': 540,\n",
              " 'latest': 541,\n",
              " 'idea': 542,\n",
              " 'ex': 543,\n",
              " 'thought': 544,\n",
              " 'march': 545,\n",
              " 'kill': 546,\n",
              " 'restaurant': 547,\n",
              " 'iran': 548,\n",
              " 'director': 549,\n",
              " 'warns': 550,\n",
              " 'chris': 551,\n",
              " 'birthday': 552,\n",
              " 'congressman': 553,\n",
              " \"what's\": 554,\n",
              " 'issues': 555,\n",
              " 'ask': 556,\n",
              " 'wrong': 557,\n",
              " 'service': 558,\n",
              " 'system': 559,\n",
              " 'birth': 560,\n",
              " 'federal': 561,\n",
              " 'sleep': 562,\n",
              " 'ceo': 563,\n",
              " 'holiday': 564,\n",
              " 'following': 565,\n",
              " 'daughter': 566,\n",
              " 'celebrates': 567,\n",
              " 'move': 568,\n",
              " 'assault': 569,\n",
              " 'mark': 570,\n",
              " 'china': 571,\n",
              " 'third': 572,\n",
              " 'rise': 573,\n",
              " 'ice': 574,\n",
              " 'someone': 575,\n",
              " 'majority': 576,\n",
              " 'cat': 577,\n",
              " 'muslim': 578,\n",
              " 'giving': 579,\n",
              " 'phone': 580,\n",
              " 'fun': 581,\n",
              " \"women's\": 582,\n",
              " 'problem': 583,\n",
              " 'abortion': 584,\n",
              " 'special': 585,\n",
              " 'wearing': 586,\n",
              " 'buy': 587,\n",
              " 'trip': 588,\n",
              " 'knows': 589,\n",
              " \"isn't\": 590,\n",
              " 'tweets': 591,\n",
              " 'less': 592,\n",
              " 'nothing': 593,\n",
              " 'girls': 594,\n",
              " 'series': 595,\n",
              " 'earth': 596,\n",
              " 'chief': 597,\n",
              " 'percent': 598,\n",
              " 'favorite': 599,\n",
              " 'washington': 600,\n",
              " 'few': 601,\n",
              " 'cover': 602,\n",
              " 'today': 603,\n",
              " 'talking': 604,\n",
              " 'meeting': 605,\n",
              " 'online': 606,\n",
              " 'syrian': 607,\n",
              " 'ted': 608,\n",
              " 'bar': 609,\n",
              " 'box': 610,\n",
              " 'hour': 611,\n",
              " 'play': 612,\n",
              " 'hours': 613,\n",
              " 'fashion': 614,\n",
              " 'late': 615,\n",
              " 'outside': 616,\n",
              " 'fox': 617,\n",
              " 'al': 618,\n",
              " 'community': 619,\n",
              " 'minute': 620,\n",
              " 'using': 621,\n",
              " 'message': 622,\n",
              " 'florida': 623,\n",
              " 'career': 624,\n",
              " 'become': 625,\n",
              " 'kid': 626,\n",
              " 'moment': 627,\n",
              " 'adorable': 628,\n",
              " 'huffpost': 629,\n",
              " 'watching': 630,\n",
              " 'stephen': 631,\n",
              " 'break': 632,\n",
              " 't': 633,\n",
              " 'un': 634,\n",
              " '2015': 635,\n",
              " 'democratic': 636,\n",
              " 'shit': 637,\n",
              " 'offers': 638,\n",
              " 'thinking': 639,\n",
              " 'george': 640,\n",
              " 'response': 641,\n",
              " 'read': 642,\n",
              " 'weekend': 643,\n",
              " 'months': 644,\n",
              " 'visit': 645,\n",
              " 'hair': 646,\n",
              " 'victims': 647,\n",
              " \"america's\": 648,\n",
              " 'told': 649,\n",
              " 'hope': 650,\n",
              " 'least': 651,\n",
              " 'different': 652,\n",
              " 'point': 653,\n",
              " 'travel': 654,\n",
              " 'front': 655,\n",
              " 'billion': 656,\n",
              " 'since': 657,\n",
              " 'rules': 658,\n",
              " 'russian': 659,\n",
              " 'feel': 660,\n",
              " 'happy': 661,\n",
              " 'protest': 662,\n",
              " 'straight': 663,\n",
              " 'gift': 664,\n",
              " 'union': 665,\n",
              " 'bus': 666,\n",
              " 'crash': 667,\n",
              " \"she's\": 668,\n",
              " 'anything': 669,\n",
              " 'dating': 670,\n",
              " 'k': 671,\n",
              " 'scott': 672,\n",
              " 'david': 673,\n",
              " 'accused': 674,\n",
              " \"obama's\": 675,\n",
              " 'taylor': 676,\n",
              " 'trailer': 677,\n",
              " 'kind': 678,\n",
              " 'names': 679,\n",
              " 'well': 680,\n",
              " 'key': 681,\n",
              " 'order': 682,\n",
              " 'true': 683,\n",
              " 'reasons': 684,\n",
              " 'cop': 685,\n",
              " 'pence': 686,\n",
              " 'reason': 687,\n",
              " 'joe': 688,\n",
              " 'dinner': 689,\n",
              " 'oil': 690,\n",
              " 'syria': 691,\n",
              " 'powerful': 692,\n",
              " 'sick': 693,\n",
              " '100': 694,\n",
              " 'brings': 695,\n",
              " 'global': 696,\n",
              " 'date': 697,\n",
              " 'lead': 698,\n",
              " 'policy': 699,\n",
              " 'spends': 700,\n",
              " 'learned': 701,\n",
              " 'millions': 702,\n",
              " 'lessons': 703,\n",
              " 'francis': 704,\n",
              " 'c': 705,\n",
              " 'struggling': 706,\n",
              " 'low': 707,\n",
              " 'discover': 708,\n",
              " 'song': 709,\n",
              " 'opens': 710,\n",
              " 'far': 711,\n",
              " 'himself': 712,\n",
              " 'girlfriend': 713,\n",
              " 'conversation': 714,\n",
              " 'schools': 715,\n",
              " 'j': 716,\n",
              " 'vows': 717,\n",
              " 'worried': 718,\n",
              " 'leave': 719,\n",
              " 'surprise': 720,\n",
              " 'kills': 721,\n",
              " 'united': 722,\n",
              " 'hate': 723,\n",
              " 'leader': 724,\n",
              " 'nfl': 725,\n",
              " 'oscar': 726,\n",
              " 'style': 727,\n",
              " 'whole': 728,\n",
              " 'anniversary': 729,\n",
              " 'turns': 730,\n",
              " 'hit': 731,\n",
              " 'waiting': 732,\n",
              " 'general': 733,\n",
              " 'fighting': 734,\n",
              " 'host': 735,\n",
              " 'immigration': 736,\n",
              " '2017': 737,\n",
              " 'killing': 738,\n",
              " 'apple': 739,\n",
              " '40': 740,\n",
              " 'prison': 741,\n",
              " '2014': 742,\n",
              " 'adds': 743,\n",
              " 'drunk': 744,\n",
              " 'weight': 745,\n",
              " \"they're\": 746,\n",
              " 'd': 747,\n",
              " 'near': 748,\n",
              " 'rubio': 749,\n",
              " 'reality': 750,\n",
              " 'weird': 751,\n",
              " 'senator': 752,\n",
              " 'feels': 753,\n",
              " 'possible': 754,\n",
              " 'moving': 755,\n",
              " 'stars': 756,\n",
              " 'signs': 757,\n",
              " 'politics': 758,\n",
              " 'sign': 759,\n",
              " 'jr': 760,\n",
              " 'leaders': 761,\n",
              " 'stand': 762,\n",
              " 'called': 763,\n",
              " 'tour': 764,\n",
              " 'returns': 765,\n",
              " 'totally': 766,\n",
              " 'reportedly': 767,\n",
              " 'massive': 768,\n",
              " 'sports': 769,\n",
              " 'major': 770,\n",
              " 'force': 771,\n",
              " 'advice': 772,\n",
              " 'breaks': 773,\n",
              " 'number': 774,\n",
              " 'bring': 775,\n",
              " 'transgender': 776,\n",
              " 'west': 777,\n",
              " 'mass': 778,\n",
              " 'spring': 779,\n",
              " 'door': 780,\n",
              " 'fall': 781,\n",
              " 'investigation': 782,\n",
              " 'tom': 783,\n",
              " 'employees': 784,\n",
              " 'test': 785,\n",
              " 'return': 786,\n",
              " 'relationship': 787,\n",
              " 'important': 788,\n",
              " 'puts': 789,\n",
              " 'iowa': 790,\n",
              " 'stage': 791,\n",
              " 'murder': 792,\n",
              " 'candidates': 793,\n",
              " 'close': 794,\n",
              " 'magazine': 795,\n",
              " 'early': 796,\n",
              " 'trans': 797,\n",
              " 'attacks': 798,\n",
              " 'side': 799,\n",
              " 'store': 800,\n",
              " 'huge': 801,\n",
              " 'artist': 802,\n",
              " 'christian': 803,\n",
              " 'die': 804,\n",
              " 'abuse': 805,\n",
              " 'longer': 806,\n",
              " 'members': 807,\n",
              " 'worst': 808,\n",
              " 'peace': 809,\n",
              " 'loses': 810,\n",
              " 'act': 811,\n",
              " 'kardashian': 812,\n",
              " 'audience': 813,\n",
              " 'five': 814,\n",
              " 'steve': 815,\n",
              " 'sean': 816,\n",
              " 'suspect': 817,\n",
              " 'prince': 818,\n",
              " 'ben': 819,\n",
              " 'suicide': 820,\n",
              " 'program': 821,\n",
              " 'decision': 822,\n",
              " 'hits': 823,\n",
              " 'lose': 824,\n",
              " 'awards': 825,\n",
              " 'queer': 826,\n",
              " 'whether': 827,\n",
              " 'cops': 828,\n",
              " 'paris': 829,\n",
              " 'workers': 830,\n",
              " 'responds': 831,\n",
              " 'push': 832,\n",
              " 'fuck': 833,\n",
              " 'iraq': 834,\n",
              " 'google': 835,\n",
              " 'leaving': 836,\n",
              " 'carolina': 837,\n",
              " 'final': 838,\n",
              " 'voice': 839,\n",
              " 'chinese': 840,\n",
              " '13': 841,\n",
              " 'lgbt': 842,\n",
              " 'executive': 843,\n",
              " 'seen': 844,\n",
              " 'jimmy': 845,\n",
              " 'given': 846,\n",
              " 'keeps': 847,\n",
              " 'shares': 848,\n",
              " 'industry': 849,\n",
              " 'biggest': 850,\n",
              " 'protesters': 851,\n",
              " 'results': 852,\n",
              " 'press': 853,\n",
              " 'center': 854,\n",
              " 'almost': 855,\n",
              " 'light': 856,\n",
              " 'risk': 857,\n",
              " 'asking': 858,\n",
              " 'emotional': 859,\n",
              " 'michelle': 860,\n",
              " 'male': 861,\n",
              " 'hands': 862,\n",
              " 'road': 863,\n",
              " 'bathroom': 864,\n",
              " 'allegations': 865,\n",
              " 'bowl': 866,\n",
              " 'begins': 867,\n",
              " 'planned': 868,\n",
              " 'homeless': 869,\n",
              " 'poor': 870,\n",
              " 'planet': 871,\n",
              " 'hoping': 872,\n",
              " 'governor': 873,\n",
              " 'non': 874,\n",
              " 'east': 875,\n",
              " 'fails': 876,\n",
              " 'cool': 877,\n",
              " 'wait': 878,\n",
              " 'moms': 879,\n",
              " 'humans': 880,\n",
              " 'cut': 881,\n",
              " 'mind': 882,\n",
              " 'defense': 883,\n",
              " 'pizza': 884,\n",
              " 'ferguson': 885,\n",
              " 'feeling': 886,\n",
              " 'amazon': 887,\n",
              " 'hall': 888,\n",
              " 'worse': 889,\n",
              " 'starting': 890,\n",
              " 'fear': 891,\n",
              " 'nasa': 892,\n",
              " 'problems': 893,\n",
              " 'check': 894,\n",
              " 'ebola': 895,\n",
              " 'role': 896,\n",
              " 'building': 897,\n",
              " 'arrested': 898,\n",
              " 'driving': 899,\n",
              " 'four': 900,\n",
              " 'scandal': 901,\n",
              " 'space': 902,\n",
              " 'moore': 903,\n",
              " 'science': 904,\n",
              " 'dance': 905,\n",
              " 'easy': 906,\n",
              " 'hand': 907,\n",
              " 'israel': 908,\n",
              " 'picture': 909,\n",
              " 'eyes': 910,\n",
              " 'voter': 911,\n",
              " \"there's\": 912,\n",
              " 'mental': 913,\n",
              " 'action': 914,\n",
              " 'doctor': 915,\n",
              " 'spend': 916,\n",
              " 'spot': 917,\n",
              " 'board': 918,\n",
              " 'chance': 919,\n",
              " 'words': 920,\n",
              " 'suggests': 921,\n",
              " 'urges': 922,\n",
              " 'williams': 923,\n",
              " 'coffee': 924,\n",
              " 'green': 925,\n",
              " 'apologizes': 926,\n",
              " 'celebrate': 927,\n",
              " 'documentary': 928,\n",
              " 'supporters': 929,\n",
              " 'rest': 930,\n",
              " 'remember': 931,\n",
              " 'depression': 932,\n",
              " 'halloween': 933,\n",
              " 'deadly': 934,\n",
              " 'louis': 935,\n",
              " 'pro': 936,\n",
              " 'oscars': 937,\n",
              " 'interview': 938,\n",
              " 'park': 939,\n",
              " 'completely': 940,\n",
              " 'harassment': 941,\n",
              " 'card': 942,\n",
              " 'university': 943,\n",
              " 'success': 944,\n",
              " 'coworker': 945,\n",
              " 'pick': 946,\n",
              " 'harvey': 947,\n",
              " 'happens': 948,\n",
              " 'throws': 949,\n",
              " 'band': 950,\n",
              " 'pregnant': 951,\n",
              " 'hear': 952,\n",
              " 'crowd': 953,\n",
              " 'deep': 954,\n",
              " 'amazing': 955,\n",
              " 'official': 956,\n",
              " 'chicken': 957,\n",
              " 'ideas': 958,\n",
              " 'refugees': 959,\n",
              " 'forward': 960,\n",
              " 'opening': 961,\n",
              " 'reveal': 962,\n",
              " 'mean': 963,\n",
              " 'simple': 964,\n",
              " 'economy': 965,\n",
              " 'reminds': 966,\n",
              " 'which': 967,\n",
              " 'turn': 968,\n",
              " 'healthy': 969,\n",
              " 'senators': 970,\n",
              " 'swift': 971,\n",
              " 'eat': 972,\n",
              " 'hurricane': 973,\n",
              " '17': 974,\n",
              " 'album': 975,\n",
              " 'despite': 976,\n",
              " \"woman's\": 977,\n",
              " 'chicago': 978,\n",
              " 'movies': 979,\n",
              " 'happened': 980,\n",
              " 'officer': 981,\n",
              " 'across': 982,\n",
              " 'desperate': 983,\n",
              " 'uses': 984,\n",
              " 'apartment': 985,\n",
              " 'plane': 986,\n",
              " 'realizes': 987,\n",
              " 'funding': 988,\n",
              " 'holding': 989,\n",
              " 'leading': 990,\n",
              " 'crime': 991,\n",
              " 'demand': 992,\n",
              " \"we're\": 993,\n",
              " 'try': 994,\n",
              " 'explains': 995,\n",
              " 'historical': 996,\n",
              " 'seeing': 997,\n",
              " 'slams': 998,\n",
              " 'residents': 999,\n",
              " 'sales': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRiNX58Rb3oJ"
      },
      "source": [
        "### Set number of words\n",
        "- Since the above 0th index doesn't have a word, add 1 to the length of the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfwq6ou8ck2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a4af33f-4ef7-4f6e-bdfc-01334a2b257b"
      },
      "source": [
        "num_words = len(tokeniser.word_index) + 1\n",
        "print(num_words)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUF1TuQa8ux0"
      },
      "source": [
        "### Load Glove Word Embeddings (3 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq5AIfRtMeZh"
      },
      "source": [
        "from keras.layers.embeddings import Embedding\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('./Data/glove.6B.200d.txt', encoding=\"utf8\")\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prHSzdQUcZhm"
      },
      "source": [
        "### Create embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elZ-T5aFGZmZ"
      },
      "source": [
        "EMBEDDING_FILE = './Data/glove.6B.200d.txt'\n",
        "\n",
        "embeddings = {}\n",
        "for o in open(EMBEDDING_FILE):\n",
        "    word = o.split(\" \")[0]\n",
        "    # print(word)\n",
        "    embd = o.split(\" \")[1:]\n",
        "    embd = np.asarray(embd, dtype='float32')\n",
        "    # print(embd)\n",
        "    embeddings[word] = embd\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((num_words, 200))\n",
        "\n",
        "for word, i in tokeniser.word_index.items():\n",
        "\tembedding_vector = embeddings.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7IbWuEX82Ra"
      },
      "source": [
        "### Define model (5 Marks)\n",
        "- Hint: Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, flatten it, then dense and dropout layers as required. \n",
        "In the end add a final dense layer with sigmoid activation for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tv168Gmc3PY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36449693-a067-4ada-b95e-75d0fb75921f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, LSTM, Bidirectional, Dense\n",
        "from keras.layers.core import Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 200, input_length = maxlen, trainable=False))\n",
        "model.add(Bidirectional(LSTM(50, batch_input_shape=(25, 1),return_sequences=True)))\n",
        "model.add(Flatten())\n",
        "#model.add(Dense(100, activation='relu'))\n",
        "# Dropout for regularization\n",
        "model.add(Dropout(0.30))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "# Output layer\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 25, 200)           2000000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 25, 100)           100400    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2500)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2500)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                25010     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 2,125,421\n",
            "Trainable params: 125,421\n",
            "Non-trainable params: 2,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoI7_8Y1cqTj"
      },
      "source": [
        "### Compile the model (3 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jJiPHeNoJ3U"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s4nmqcecw3a"
      },
      "source": [
        "### Fit the model (4 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN789zNnJ5PL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad8afe2-d26a-43b0-a218-ede3c891cd57"
      },
      "source": [
        "\n",
        "history = model.fit(training_padded, training_labels, \n",
        "                    validation_data=(testing_padded, testing_labels), \n",
        "                    batch_size=128, epochs=50, verbose=1)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 0.6131 - acc: 0.6389 - val_loss: 0.5509 - val_acc: 0.7093\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.5445 - acc: 0.7086 - val_loss: 0.5390 - val_acc: 0.7160\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.5256 - acc: 0.7256 - val_loss: 0.5224 - val_acc: 0.7294\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.5108 - acc: 0.7355 - val_loss: 0.5107 - val_acc: 0.7418\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4937 - acc: 0.7510 - val_loss: 0.5001 - val_acc: 0.7454\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4861 - acc: 0.7542 - val_loss: 0.4939 - val_acc: 0.7454\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4714 - acc: 0.7637 - val_loss: 0.4897 - val_acc: 0.7533\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4646 - acc: 0.7671 - val_loss: 0.4804 - val_acc: 0.7554\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4516 - acc: 0.7732 - val_loss: 0.4773 - val_acc: 0.7598\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4423 - acc: 0.7784 - val_loss: 0.4730 - val_acc: 0.7650\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4325 - acc: 0.7848 - val_loss: 0.4808 - val_acc: 0.7577\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4212 - acc: 0.7947 - val_loss: 0.4671 - val_acc: 0.7733\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4122 - acc: 0.8036 - val_loss: 0.4919 - val_acc: 0.7601\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4025 - acc: 0.8072 - val_loss: 0.4587 - val_acc: 0.7780\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3873 - acc: 0.8167 - val_loss: 0.4493 - val_acc: 0.7851\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3818 - acc: 0.8188 - val_loss: 0.4521 - val_acc: 0.7792\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3731 - acc: 0.8252 - val_loss: 0.4462 - val_acc: 0.7909\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3595 - acc: 0.8344 - val_loss: 0.4746 - val_acc: 0.7842\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3519 - acc: 0.8373 - val_loss: 0.4360 - val_acc: 0.7981\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3363 - acc: 0.8470 - val_loss: 0.4431 - val_acc: 0.8011\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3365 - acc: 0.8469 - val_loss: 0.4362 - val_acc: 0.8001\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3217 - acc: 0.8557 - val_loss: 0.4515 - val_acc: 0.8028\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3145 - acc: 0.8588 - val_loss: 0.4400 - val_acc: 0.8047\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3023 - acc: 0.8656 - val_loss: 0.4411 - val_acc: 0.8034\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2955 - acc: 0.8706 - val_loss: 0.4570 - val_acc: 0.8069\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2885 - acc: 0.8729 - val_loss: 0.4555 - val_acc: 0.8055\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2753 - acc: 0.8806 - val_loss: 0.4595 - val_acc: 0.8037\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2686 - acc: 0.8843 - val_loss: 0.4773 - val_acc: 0.8078\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2589 - acc: 0.8880 - val_loss: 0.4676 - val_acc: 0.8080\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2538 - acc: 0.8920 - val_loss: 0.4959 - val_acc: 0.7942\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2440 - acc: 0.8938 - val_loss: 0.4867 - val_acc: 0.8052\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2336 - acc: 0.9014 - val_loss: 0.4848 - val_acc: 0.8111\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2255 - acc: 0.9058 - val_loss: 0.4758 - val_acc: 0.8164\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.2182 - acc: 0.9091 - val_loss: 0.5127 - val_acc: 0.8117\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.2137 - acc: 0.9108 - val_loss: 0.5149 - val_acc: 0.8098\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.2134 - acc: 0.9116 - val_loss: 0.5089 - val_acc: 0.8128\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1970 - acc: 0.9177 - val_loss: 0.5152 - val_acc: 0.8093\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1902 - acc: 0.9201 - val_loss: 0.5566 - val_acc: 0.8113\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.1850 - acc: 0.9249 - val_loss: 0.5604 - val_acc: 0.8096\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1757 - acc: 0.9298 - val_loss: 0.5590 - val_acc: 0.8092\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1800 - acc: 0.9254 - val_loss: 0.5655 - val_acc: 0.8128\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1676 - acc: 0.9300 - val_loss: 0.6269 - val_acc: 0.8143\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1580 - acc: 0.9364 - val_loss: 0.5907 - val_acc: 0.8120\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1561 - acc: 0.9360 - val_loss: 0.6593 - val_acc: 0.8101\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1406 - acc: 0.9440 - val_loss: 0.6802 - val_acc: 0.8074\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1450 - acc: 0.9428 - val_loss: 0.7167 - val_acc: 0.7977\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1357 - acc: 0.9458 - val_loss: 0.6878 - val_acc: 0.8099\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1332 - acc: 0.9470 - val_loss: 0.6606 - val_acc: 0.8069\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1286 - acc: 0.9485 - val_loss: 0.7084 - val_acc: 0.8113\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1171 - acc: 0.9541 - val_loss: 0.7785 - val_acc: 0.8113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4_Ax8zj6Gba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7368b036-2d11-46d4-e465-2560b608bdb0"
      },
      "source": [
        "score,acc = model.evaluate(training_padded, training_labels, verbose = 0, batch_size = 128)\n",
        "print(\"TRAIN : score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))\n",
        "\n",
        "score12,acc12 = model.evaluate(testing_padded, testing_labels, verbose = 0, batch_size = 128)\n",
        "print(\"TEST : score: %.2f\" % (score12))\n",
        "print(\"acc: %.2f\" % (acc12))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN : score: 0.10\n",
            "acc: 0.96\n",
            "TEST : score: 0.78\n",
            "acc: 0.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlHglP0cQTuC"
      },
      "source": [
        "**Trying other models with variations, anyways!!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV_GzVQyP43r",
        "outputId": "c9490fdd-d63d-4958-9858-35b2d6c76333"
      },
      "source": [
        "## Model2 :  without Bidirectional layer\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(max_features, 200,input_length = maxlen, trainable=False))\n",
        "model2.add(LSTM(100, batch_input_shape=(25, 1),return_sequences=True))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dropout(0.15))\n",
        "model2.add(Dense(80, activation='relu'))\n",
        "# Output layer\n",
        "model2.add(Dense(1,activation='sigmoid'))\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "history2 = model2.fit(training_padded, training_labels, \n",
        "                    validation_data=(testing_padded, testing_labels), \n",
        "                    batch_size=128, epochs=50, verbose=1)\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.5711 - acc: 0.6823 - val_loss: 0.5393 - val_acc: 0.7124\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.5194 - acc: 0.7298 - val_loss: 0.5136 - val_acc: 0.7331\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.4990 - acc: 0.7470 - val_loss: 0.5098 - val_acc: 0.7375\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.4889 - acc: 0.7518 - val_loss: 0.5110 - val_acc: 0.7342\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.4751 - acc: 0.7600 - val_loss: 0.4989 - val_acc: 0.7424\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.4613 - acc: 0.7688 - val_loss: 0.4870 - val_acc: 0.7470\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.4513 - acc: 0.7743 - val_loss: 0.4867 - val_acc: 0.7463\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.4390 - acc: 0.7828 - val_loss: 0.4872 - val_acc: 0.7457\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.4273 - acc: 0.7886 - val_loss: 0.4790 - val_acc: 0.7553\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.4150 - acc: 0.7977 - val_loss: 0.4771 - val_acc: 0.7559\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.4025 - acc: 0.8061 - val_loss: 0.4770 - val_acc: 0.7569\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.3913 - acc: 0.8117 - val_loss: 0.4757 - val_acc: 0.7643\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.3762 - acc: 0.8205 - val_loss: 0.4791 - val_acc: 0.7638\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.3621 - acc: 0.8282 - val_loss: 0.4878 - val_acc: 0.7677\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.3482 - acc: 0.8361 - val_loss: 0.4705 - val_acc: 0.7752\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.3314 - acc: 0.8453 - val_loss: 0.5128 - val_acc: 0.7589\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.3202 - acc: 0.8553 - val_loss: 0.4778 - val_acc: 0.7755\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.3018 - acc: 0.8621 - val_loss: 0.4958 - val_acc: 0.7813\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.2933 - acc: 0.8675 - val_loss: 0.4905 - val_acc: 0.7789\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.2803 - acc: 0.8715 - val_loss: 0.4998 - val_acc: 0.7807\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.2619 - acc: 0.8818 - val_loss: 0.5060 - val_acc: 0.7849\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.2448 - acc: 0.8929 - val_loss: 0.5222 - val_acc: 0.7873\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.2334 - acc: 0.8981 - val_loss: 0.5446 - val_acc: 0.7825\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.2242 - acc: 0.8998 - val_loss: 0.5682 - val_acc: 0.7800\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.2076 - acc: 0.9093 - val_loss: 0.5736 - val_acc: 0.7878\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.1951 - acc: 0.9183 - val_loss: 0.5863 - val_acc: 0.7879\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.1840 - acc: 0.9238 - val_loss: 0.6160 - val_acc: 0.7906\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.1692 - acc: 0.9282 - val_loss: 0.6839 - val_acc: 0.7813\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.1594 - acc: 0.9319 - val_loss: 0.6572 - val_acc: 0.7801\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.1574 - acc: 0.9356 - val_loss: 0.6825 - val_acc: 0.7906\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.1372 - acc: 0.9450 - val_loss: 0.7052 - val_acc: 0.7894\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.1371 - acc: 0.9441 - val_loss: 0.7132 - val_acc: 0.7968\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.1258 - acc: 0.9484 - val_loss: 0.7274 - val_acc: 0.7962\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.1157 - acc: 0.9536 - val_loss: 0.8163 - val_acc: 0.7810\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.1024 - acc: 0.9586 - val_loss: 0.8922 - val_acc: 0.7893\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0944 - acc: 0.9618 - val_loss: 0.8999 - val_acc: 0.7918\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0932 - acc: 0.9627 - val_loss: 0.8881 - val_acc: 0.7881\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0882 - acc: 0.9650 - val_loss: 0.9294 - val_acc: 0.7819\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0789 - acc: 0.9687 - val_loss: 0.9872 - val_acc: 0.7813\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0778 - acc: 0.9690 - val_loss: 1.0373 - val_acc: 0.7863\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0706 - acc: 0.9731 - val_loss: 1.0415 - val_acc: 0.7903\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0616 - acc: 0.9765 - val_loss: 1.1060 - val_acc: 0.7855\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0705 - acc: 0.9729 - val_loss: 1.0891 - val_acc: 0.7933\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0613 - acc: 0.9776 - val_loss: 1.0446 - val_acc: 0.7905\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.0532 - acc: 0.9800 - val_loss: 1.1979 - val_acc: 0.7869\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0483 - acc: 0.9810 - val_loss: 1.2400 - val_acc: 0.7837\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0510 - acc: 0.9804 - val_loss: 1.2393 - val_acc: 0.7891\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0432 - acc: 0.9846 - val_loss: 1.3121 - val_acc: 0.7840\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0447 - acc: 0.9832 - val_loss: 1.2971 - val_acc: 0.7824\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.0344 - acc: 0.9877 - val_loss: 1.3444 - val_acc: 0.7870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DtZnbtPP5Cu",
        "outputId": "15d26447-367b-44e3-bfda-ac2c6010bedd"
      },
      "source": [
        "## Model3:  with Bidirectional layer but lesser dropout\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(max_features, 200, input_length = maxlen, trainable=False))\n",
        "model3.add(Bidirectional(LSTM(10, batch_input_shape=(25, 1),return_sequences=True)))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dropout(0.10))\n",
        "model3.add(Dense(10, activation='relu'))\n",
        "# Output layer\n",
        "model3.add(Dense(1,activation='sigmoid'))\n",
        "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "history3 = model3.fit(training_padded, training_labels, \n",
        "                    validation_data=(testing_padded, testing_labels), \n",
        "                    batch_size=128, epochs=50, verbose=1)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 0.6254 - acc: 0.6299 - val_loss: 0.5529 - val_acc: 0.7056\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.5417 - acc: 0.7093 - val_loss: 0.5309 - val_acc: 0.7258\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.5238 - acc: 0.7263 - val_loss: 0.5202 - val_acc: 0.7324\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.5139 - acc: 0.7321 - val_loss: 0.5105 - val_acc: 0.7327\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.5022 - acc: 0.7441 - val_loss: 0.5038 - val_acc: 0.7345\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4923 - acc: 0.7497 - val_loss: 0.5094 - val_acc: 0.7372\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4846 - acc: 0.7527 - val_loss: 0.4983 - val_acc: 0.7399\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4796 - acc: 0.7569 - val_loss: 0.4928 - val_acc: 0.7470\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4730 - acc: 0.7620 - val_loss: 0.4925 - val_acc: 0.7488\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4670 - acc: 0.7657 - val_loss: 0.4861 - val_acc: 0.7506\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4599 - acc: 0.7712 - val_loss: 0.4822 - val_acc: 0.7578\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4544 - acc: 0.7752 - val_loss: 0.4798 - val_acc: 0.7590\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4474 - acc: 0.7795 - val_loss: 0.4751 - val_acc: 0.7607\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4419 - acc: 0.7832 - val_loss: 0.4730 - val_acc: 0.7619\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4346 - acc: 0.7864 - val_loss: 0.4679 - val_acc: 0.7647\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4281 - acc: 0.7916 - val_loss: 0.4659 - val_acc: 0.7679\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4204 - acc: 0.7944 - val_loss: 0.4694 - val_acc: 0.7673\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4157 - acc: 0.8014 - val_loss: 0.4576 - val_acc: 0.7721\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.4101 - acc: 0.8017 - val_loss: 0.4618 - val_acc: 0.7742\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.4055 - acc: 0.8068 - val_loss: 0.4597 - val_acc: 0.7744\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.3974 - acc: 0.8097 - val_loss: 0.4468 - val_acc: 0.7797\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3929 - acc: 0.8147 - val_loss: 0.4486 - val_acc: 0.7831\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3853 - acc: 0.8180 - val_loss: 0.4443 - val_acc: 0.7885\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3820 - acc: 0.8216 - val_loss: 0.4426 - val_acc: 0.7891\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3784 - acc: 0.8222 - val_loss: 0.4373 - val_acc: 0.7890\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3721 - acc: 0.8245 - val_loss: 0.4369 - val_acc: 0.7912\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3634 - acc: 0.8309 - val_loss: 0.4356 - val_acc: 0.7918\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3581 - acc: 0.8343 - val_loss: 0.4378 - val_acc: 0.7930\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3586 - acc: 0.8345 - val_loss: 0.4308 - val_acc: 0.7983\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3502 - acc: 0.8380 - val_loss: 0.4343 - val_acc: 0.7995\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3445 - acc: 0.8426 - val_loss: 0.4356 - val_acc: 0.8002\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3398 - acc: 0.8448 - val_loss: 0.4303 - val_acc: 0.8026\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3330 - acc: 0.8490 - val_loss: 0.4398 - val_acc: 0.7969\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3290 - acc: 0.8512 - val_loss: 0.4339 - val_acc: 0.8025\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3237 - acc: 0.8561 - val_loss: 0.4339 - val_acc: 0.8050\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3217 - acc: 0.8550 - val_loss: 0.4267 - val_acc: 0.8031\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3200 - acc: 0.8543 - val_loss: 0.4224 - val_acc: 0.8099\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3091 - acc: 0.8635 - val_loss: 0.4329 - val_acc: 0.8078\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3124 - acc: 0.8602 - val_loss: 0.4229 - val_acc: 0.8065\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3016 - acc: 0.8663 - val_loss: 0.4354 - val_acc: 0.8065\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2999 - acc: 0.8685 - val_loss: 0.4430 - val_acc: 0.8046\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2925 - acc: 0.8688 - val_loss: 0.4467 - val_acc: 0.7986\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2895 - acc: 0.8729 - val_loss: 0.4350 - val_acc: 0.8107\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2864 - acc: 0.8741 - val_loss: 0.4413 - val_acc: 0.8078\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2804 - acc: 0.8772 - val_loss: 0.4395 - val_acc: 0.8125\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2737 - acc: 0.8818 - val_loss: 0.4388 - val_acc: 0.8061\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2724 - acc: 0.8837 - val_loss: 0.4535 - val_acc: 0.8046\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2724 - acc: 0.8827 - val_loss: 0.4576 - val_acc: 0.8074\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2685 - acc: 0.8834 - val_loss: 0.4458 - val_acc: 0.8058\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2651 - acc: 0.8869 - val_loss: 0.4586 - val_acc: 0.8096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oI4yyov4Pb7",
        "outputId": "818123e9-3de4-4108-9a44-3d77d85a5b1d"
      },
      "source": [
        "## Model4:  with Bidirectional layer \n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(Embedding(max_features, 200, input_length = maxlen, trainable=False))\n",
        "model4.add(Bidirectional(LSTM(10, batch_input_shape=(25, 1),return_sequences=True)))\n",
        "model4.add(Flatten())\n",
        "model4.add(Dropout(0.05))\n",
        "model4.add(Dense(100, activation='relu'))\n",
        "# Output layer\n",
        "model4.add(Dense(1,activation='sigmoid'))\n",
        "model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "history4 = model4.fit(training_padded, training_labels, \n",
        "                    validation_data=(testing_padded, testing_labels), \n",
        "                    batch_size=128, epochs=50, verbose=1)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 0.6201 - acc: 0.6371 - val_loss: 0.5527 - val_acc: 0.7074\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.5317 - acc: 0.7214 - val_loss: 0.5228 - val_acc: 0.7306\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.5106 - acc: 0.7385 - val_loss: 0.5194 - val_acc: 0.7270\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4958 - acc: 0.7491 - val_loss: 0.5022 - val_acc: 0.7446\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4863 - acc: 0.7559 - val_loss: 0.4953 - val_acc: 0.7470\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4763 - acc: 0.7629 - val_loss: 0.4951 - val_acc: 0.7491\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4672 - acc: 0.7685 - val_loss: 0.4879 - val_acc: 0.7529\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4579 - acc: 0.7746 - val_loss: 0.4821 - val_acc: 0.7577\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4514 - acc: 0.7762 - val_loss: 0.4754 - val_acc: 0.7598\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4426 - acc: 0.7849 - val_loss: 0.4728 - val_acc: 0.7622\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4333 - acc: 0.7905 - val_loss: 0.4691 - val_acc: 0.7655\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4259 - acc: 0.7921 - val_loss: 0.4638 - val_acc: 0.7709\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4159 - acc: 0.7995 - val_loss: 0.4650 - val_acc: 0.7740\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.4083 - acc: 0.8069 - val_loss: 0.4562 - val_acc: 0.7740\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3982 - acc: 0.8088 - val_loss: 0.4555 - val_acc: 0.7795\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3897 - acc: 0.8150 - val_loss: 0.4499 - val_acc: 0.7881\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3814 - acc: 0.8196 - val_loss: 0.4626 - val_acc: 0.7718\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3743 - acc: 0.8223 - val_loss: 0.4592 - val_acc: 0.7843\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3641 - acc: 0.8289 - val_loss: 0.4433 - val_acc: 0.7938\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3592 - acc: 0.8333 - val_loss: 0.4445 - val_acc: 0.7869\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3509 - acc: 0.8362 - val_loss: 0.4442 - val_acc: 0.7986\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3407 - acc: 0.8432 - val_loss: 0.4351 - val_acc: 0.7969\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3347 - acc: 0.8477 - val_loss: 0.4372 - val_acc: 0.7984\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3278 - acc: 0.8497 - val_loss: 0.4291 - val_acc: 0.8049\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3243 - acc: 0.8530 - val_loss: 0.4348 - val_acc: 0.7995\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3134 - acc: 0.8578 - val_loss: 0.4352 - val_acc: 0.8066\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3064 - acc: 0.8635 - val_loss: 0.4306 - val_acc: 0.8093\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.3034 - acc: 0.8630 - val_loss: 0.4290 - val_acc: 0.8052\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2949 - acc: 0.8684 - val_loss: 0.4365 - val_acc: 0.8026\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2891 - acc: 0.8730 - val_loss: 0.4370 - val_acc: 0.8019\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2883 - acc: 0.8695 - val_loss: 0.4557 - val_acc: 0.7954\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2812 - acc: 0.8776 - val_loss: 0.4338 - val_acc: 0.8075\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2735 - acc: 0.8777 - val_loss: 0.4337 - val_acc: 0.8071\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2650 - acc: 0.8824 - val_loss: 0.4402 - val_acc: 0.8089\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2595 - acc: 0.8877 - val_loss: 0.4495 - val_acc: 0.8049\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2605 - acc: 0.8861 - val_loss: 0.4475 - val_acc: 0.8041\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2531 - acc: 0.8887 - val_loss: 0.4537 - val_acc: 0.8122\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2445 - acc: 0.8949 - val_loss: 0.4551 - val_acc: 0.8099\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2442 - acc: 0.8959 - val_loss: 0.4416 - val_acc: 0.8081\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2419 - acc: 0.8957 - val_loss: 0.4485 - val_acc: 0.8084\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2318 - acc: 0.9010 - val_loss: 0.4623 - val_acc: 0.8105\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2271 - acc: 0.9017 - val_loss: 0.4539 - val_acc: 0.8131\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2212 - acc: 0.9053 - val_loss: 0.4853 - val_acc: 0.8081\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2212 - acc: 0.9058 - val_loss: 0.4632 - val_acc: 0.8092\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2144 - acc: 0.9110 - val_loss: 0.4748 - val_acc: 0.8111\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2127 - acc: 0.9096 - val_loss: 0.4758 - val_acc: 0.8090\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2100 - acc: 0.9097 - val_loss: 0.4684 - val_acc: 0.8140\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2056 - acc: 0.9138 - val_loss: 0.4785 - val_acc: 0.8134\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1952 - acc: 0.9184 - val_loss: 0.4944 - val_acc: 0.8066\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1930 - acc: 0.9190 - val_loss: 0.4992 - val_acc: 0.8119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPyJn1KsymQQ"
      },
      "source": [
        "## Comparing model's performance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYELI5MBSXso",
        "outputId": "d3ae7586-fc76-424d-85bd-8d98baab33d2"
      },
      "source": [
        "print(\"Model1 \\n Train score: \" ,score,\" acc:\" , acc)\n",
        "print(\"Test : score: \" ,score12,\" acc:\" , acc12)\n",
        "\n",
        "\n",
        "score21,acc21 = model2.evaluate(training_padded, training_labels, verbose = 0, batch_size = 128)\n",
        "score22,acc22 = model2.evaluate(testing_padded, testing_labels, verbose = 0, batch_size = 128)\n",
        "print(\"\\n Model2 \\nTrain : score2: \" ,score21,\" acc2:\" , acc21)\n",
        "print(\"Test :score2: \" ,score22,\" acc2:\" , acc22)\n",
        "\n",
        "\n",
        "score31,acc31 = model3.evaluate(training_padded, training_labels, verbose = 0, batch_size = 128)\n",
        "score32,acc32 = model3.evaluate(testing_padded, testing_labels, verbose = 0, batch_size = 128)\n",
        "print(\"\\n Model3 \\nTrain :score3: \", score31,\" acc3:\",  acc31)\n",
        "print(\"Test :score3: \", score32,\" acc32:\",  acc32)\n",
        "\n",
        "score41,acc41 = model4.evaluate(training_padded, training_labels, verbose = 0, batch_size = 128)\n",
        "score42,acc42 = model4.evaluate(testing_padded, testing_labels, verbose = 0, batch_size = 128)\n",
        "print(\"\\n Model4 \\nTrain :score: \", score41,\" acc:\",  acc41)\n",
        "print(\"Test :score: \", score42,\" acc:\",  acc42)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model1 \n",
            " Train score:  0.09559154510498047  acc: 0.9642072916030884\n",
            "Test : score:  0.7785038948059082  acc: 0.8112924695014954\n",
            "\n",
            " Model2 \n",
            "Train : score2:  0.022687699645757675  acc2: 0.9933606386184692\n",
            "Test :score2:  1.3443611860275269  acc2: 0.7870301008224487\n",
            "\n",
            " Model3 \n",
            "Train :score3:  0.24310870468616486  acc3: 0.8982128500938416\n",
            "Test :score3:  0.45864206552505493  acc32: 0.8096450567245483\n",
            "\n",
            " Model4 \n",
            "Train :score:  0.1672070473432541  acc: 0.9330571293830872\n",
            "Test :score:  0.49915528297424316  acc: 0.8118915557861328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJTK9sZ558x8"
      },
      "source": [
        "## Clearly model 4 is best fit here, hence using it to plot accuracy and loss below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iKA3PjJTixv"
      },
      "source": [
        "**Plot the Result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "Eq2cl8FLa5IN",
        "outputId": "07f4b737-7a68-487b-a85c-4f42a9ea38df"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history4.history['acc'])\n",
        "#plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train','Test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('model_accuracy.png')\n",
        "# summarize history for loss\n",
        "plt.plot(history4.history['loss'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train','Test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('model_loss.png')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxhqezndbMIp"
      },
      "source": [
        "#Save the model\n",
        "model_json = model4.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model4.save_weights(\"/modelSarcasticOrNot.h5\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ismQ6kjk6gsz"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}